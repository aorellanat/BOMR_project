{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Mobile robots project\n",
    "\n",
    "<div style=\"border: 2px solid #4CAF50; border-radius: 10px; padding: 15px; background-color: #E8F5E9; color: #333;\">\n",
    "    <strong>T30 Members:</strong>\n",
    "    <ul>\n",
    "        <li>Jiwon You</li>\n",
    "        <li>Adriana Nancy Orellana Torrico</li>\n",
    "        <li>Charles Froessel</li>\n",
    "        <li>Johann Lugon-Moulin</li>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Project description\n",
    "\n",
    "## 1. Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- A good feature needs to be easy to extract and easy to match, robust to change in illumination, camera viewpoint and highly distinctive.\n",
    "- From 3D to 2D: perspective projection\n",
    "- Gaussian smoothing: removes high-frequency noise from the image with a gaussian kernel G\n",
    "- Edge detection: canny edge filter (combination of smoothing + edge detector into one operator) is an optimal detector, to reduce its cost we can numerically approximate its behavior computing the edge direction and magnitude with Sobel.\n",
    "- Sobel filter: from a row image convert to gray scale, then filter the image with gaussian or sobel filter, apply thresholding to get the edges, and finally non-maximum suppression to get the final edges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Components\n",
    "\n",
    "*TODO:* For each section, please explain how your imlementation works and how you have tested it. You can add diagrams, images or videos to make it easier to understand and show that your components are working as expected. Don't forget to cite external sources if you used any (even course materials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.1. Computer vision and image processing\n",
    "\n",
    "**Responsible:** Adriana Nancy Orellana Torrico\n",
    "\n",
    "**Slide intructions:** Your environment has to contain a set of obstacles that the Thymio avoids through global navigation. That is to say, the Thymio should avoid these obstacles without using the sensors to detect them. (remove when completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.2. Path planning\n",
    "\n",
    "**Responsible:** Charles Froessel\n",
    "\n",
    "**Slides intructions:** The objective is that the Thymio goes from an arbitrary position in the map to a target that can be placed anywhere in the environment. These will be changed during the demo to see how your system performs. (remove when completed) \n",
    "\n",
    "**Link for schematics (Use epfl account):** https://epflch-my.sharepoint.com/:p:/r/personal/charles_froessel_epfl_ch/_layouts/15/doc.aspx?sourcedoc=%7B20d9373d-95f6-4339-9879-352d763cab56%7D&action=edit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Pose estimation\n",
    "\n",
    "**Responsible:** Jiwon You\n",
    "\n",
    "#### 2.3.1 System Identification of a differetial drive robot\n",
    "Below are the names to denote state/control variables of Thymio. \\\n",
    "\\\n",
    "$u_l$ = left motor control input, `motor.left.target` \\\n",
    "$u_r$ = right motor control input, `motor.right.target` \\\n",
    "$u_{l,m}$ = measured left motor speed, `motor.left.speed` \\\n",
    "$u_{r,m}$ = measured left motor speed, `motor.right.speed` \\\n",
    "$v_{l}$ = linear velocity of left wheel \\\n",
    "$v_{r}$ = linear velocity of right wheel \\\n",
    "$v$ = linear velocity of Thymio \\\n",
    "$w$ = angular velocity of Thymio \n",
    "\n",
    "First, in `calibration.ipynb` I ran calibration code from exercise 8 to discover relationship between motor speed and linear velocity of Thymio. We will mainly use $u_l$ and $u_r$ around 100 to control Thymio, so we investigate linear velocity and motor speed variance at $u=100$. Moreover, we assume that conversion between motor speed and linear velocity is linear around this point. \\\n",
    "![My Image](figure/ground_sensor.png) \\\n",
    "Knowing that there is a thin white stripe between black blocks every 5cm, we can detect peaks from ground sensor and compute linear speed from the time it took to cross 6 blocks.\\\n",
    "It returned linear velocity = `3.26cm/s` for motor speed 100, and thus conversion factor from motor speed to linear velocity was `0.0326`. \\\n",
    "![My Image](figure/target_and_measured_speed_of_motor.png)\\\n",
    "In the histogram below, measured motor speed forms a Gaussian distribution around motor target speed of 100.\\\n",
    "![My Image](figure/measured_motor_speed_histogram.png)\n",
    "\n",
    "With $\\alpha$ as conversion factor and $L$ as Thymio wheel axle length,  \\\n",
    "$v_l = \\alpha u_l$ \\\n",
    "$v_r = \\alpha u_r$ \\\n",
    "$v = \\frac{v_l + v_r}{2}$ \\\n",
    "$w = \\frac{v_r - v_l}{L}$ \\\n",
    "Conversion between $v,w$ and $u_l, u_r$ is implemented in `utils.py`.\n",
    "```py\n",
    "    wheel_axle_length = 9.5 # in cm\n",
    "    thymio_speed_to_cms = 0.03260\n",
    "    def from_u_to_vw(ul, ur):\n",
    "        thymio_speed_to_cms = 0.03260\n",
    "        A = thymio_speed_to_cms* np.array([[0.5, 0.5],[-1/wheel_axle_length, 1/wheel_axle_length]])\n",
    "        # vl = thymio_speed_to_cms * ul\n",
    "        # vr = thymio_speed_to_cms * ur\n",
    "        # v = (vl + vr) / 2\n",
    "        # w = (vr - vl) / wheel_axle_length\n",
    "        vw = A@np.array([ul, ur]) \n",
    "        return vw[0], vw[1] # returns v, w in cm/s, rad/s\n",
    "\n",
    "    def from_vw_to_u(v,w):\n",
    "        A = thymio_speed_to_cms* np.array([[0.5, 0.5],[-1/wheel_axle_length, 1/wheel_axle_length]])\n",
    "        A_inv = np.linalg.inv(A)\n",
    "        ulur = A_inv @ np.array([v,w]) \n",
    "        return int(ulur[0]), int(ulur[1]) # returns ul, ur as int\n",
    "```\n",
    "Let $X = (x,y,\\theta, v, w)^{T}$ denote Thymio state. Discrete time motion model of Thymio is as follows.\n",
    "$$\n",
    "\\begin{align*}\n",
    "X_{i+1} \n",
    "&= f(X_i, u_i) \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "x_i + v_i\\cdot cos(\\theta_i)\\Delta t\\\\\n",
    "y_i + v_i\\cdot sin(\\theta_i)\\Delta t\\\\\n",
    "\\theta_i + w_i\\cdot\\Delta t \\\\\n",
    "v_{i+1}\\\\\n",
    "w_{i+1}\n",
    "\\end{bmatrix} \\\\\n",
    "(v_{i+1}, w_{i+1}) &= from\\_u\\_to\\_vw(u_i)\n",
    "\\end{align*}\n",
    "$$ //\n",
    "This is implemented in `ExtendedKalmanFilter.move(u)` of `kalman.py`.\\\n",
    "```py\n",
    "    def move(self, u):\n",
    "        assert(u.shape[0] == 2) # u is np.array containing v_,w_\n",
    "        x,y,theta,v,w = self.X\n",
    "        v_, w_ = u\n",
    "        self.X[0] = x + v*np.cos(theta)*self.dt \n",
    "        self.X[1] = y + v*np.sin(theta)*self.dt\n",
    "        self.X[2] = self.clip_theta(theta + w * self.dt)\n",
    "        self.X[3] = v_ \n",
    "        self.X[4] = w_\n",
    "``` \n",
    "\n",
    "#### 2.3.2 Process and measurement noise\n",
    "For Kalman Filter, let Q denote process noise matrix, R measurement noise matrix, $R_c$ camera noise matrix, $R_{vw}$ linear/angular velocity measurement noise matrix. Since we can't really estimate process noise, I used empirical tuning for Q. \n",
    "$$\n",
    "R = \n",
    "\\begin{bmatrix}\n",
    "R_c & 0 \\\\\n",
    "0 & R_{vw}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Measurement noise is split into camera noise and vw noise. It is safe to assume that camera noise and vw noise are uncorrelated, and thus R is in block diagonal form. \\\n",
    "Camera measurements are faily accurate, and we can use a small value for camera noise. However, when aruco marker on Thymio is blocked, camera cannot detect Thymio. For such case, camera will return $(x_{cam}, y_{cam}, \\theta_{cam}) = (0, 0, 0)$ and camera noise will be set to infinity, which excludes camera measurement from updating Thymio state. This is implemented in `ExtendedKalmanFilter.switch_mode()` of `kalman.py`.\\\n",
    "```py\n",
    "    NOISE_COV_VW = np.array([[0.01285577, 0.00072932],\n",
    "                    [0.00072932, 0.00056978]]) # from calibration.ipynb\n",
    "    NOISE_COV_CAMERA = 0.0001*np.eye(3)\n",
    "    NOISE_COV_CAMERA_BLOCKED=9999999*np.eye(3)\n",
    "    PROCESS_COV = 0.01*np.eye(5)\n",
    "    def switch_mode(self, camera_blocked):\n",
    "        if camera_blocked and self.camera_available:\n",
    "            self.R[0:3, 0:3] = NOISE_COV_CAMERA_BLOCKED\n",
    "            self.camera_available = False\n",
    "        elif not camera_blocked and not self.camera_available:\n",
    "            self.R[0:3,0:3] = NOISE_COV_CAMERA\n",
    "            self.camera_available = True\n",
    "``` \n",
    "We have previously seen that motor speed measurement noise resembles Gaussian. Since we have direct access to motor speed measurement, we can easily compute motor speed variance. We assume that noise from left and right motor are uncorrelated.\\\n",
    "![My Image](figure/target_and_measured_speed_of_motor.png)\\\n",
    "Then using linear transformation, we can convert motor speed variance to linear/angular velocity variance. As in 2.3.1, $\\alpha$ denotes Thymio speed conversion factor.\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\begin{bmatrix}\n",
    "v \\\\\n",
    "w\n",
    "\\end{bmatrix}\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\alpha}{2} & \\frac{\\alpha}{2} \\\\\n",
    "\\frac{-\\alpha}{L} & \\frac{\\alpha}{L} \n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix}\n",
    "u_l \\\\\n",
    "u_r\n",
    "\\end{bmatrix} = A\\cdot u \\\\\n",
    "\\Sigma_{u} &= \n",
    "\\begin{bmatrix}\n",
    "\\sigma_{ul}^2 & 0 \\\\\n",
    "0 & \\sigma_{ur}^2\n",
    "\\end{bmatrix} \\\\\n",
    "\\Sigma_{vw} &= A\\cdot\\Sigma_{u}\\cdot A^T\n",
    "\\end{align*}\n",
    "$$ //\n",
    "```py\n",
    "    var_l_speed = np.var(l_speed[idx:]) # took from idx to avoid the initial transient and devid by the conversion factor\n",
    "    var_r_speed = np.var(r_speed[idx:])\n",
    "    wheel_axle_length = 9.5 # in cm\n",
    "    A = thymio_speed_to_cms* np.array([[0.5, 0.5],[-1/wheel_axle_length, 1/wheel_axle_length]]) # (v,w) = A @ (ul, ur)\n",
    "    cov_vw = A @ np.array([[var_l_speed,0],[0, var_r_speed]]) @ A.T\n",
    "```\n",
    "$$\n",
    "R_{vw} =\n",
    "\\begin{bmatrix}\n",
    "0.01286 & 0.00073 \\\\\n",
    "0.00073 & 0.00057\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Note that $R_{vw}$ is not diagonal. This agrees with our intuition that linear/angular velocity noise are correlated.\n",
    "#### 2.3.3 Extended Kalman Filter implementation\n",
    "Since our Thymio is a time-variant nonlinear system and noises can be assumed as Gaussian, we are using Extended Kalman Filter.\n",
    "$$\n",
    "\\begin{align*}\n",
    "X_{i+1} \n",
    "&= f(X_i, u_i) \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "x_i + v_i\\cdot cos(\\theta_i)\\Delta t\\\\\n",
    "y_i + v_i\\cdot sin(\\theta_i)\\Delta t\\\\\n",
    "\\theta_i + w_i\\cdot\\Delta t \\\\\n",
    "v_{i+1}\\\\\n",
    "w_{i+1}\n",
    "\\end{bmatrix} \\\\\n",
    "y &= h(X) = X\n",
    "\\end{align*}\n",
    "$$ \n",
    "First we compute Jacobian of $f(X_i, u_i)$ to linearize our system.\n",
    "$$\n",
    "\\begin{align*}\n",
    "F\n",
    "&= \\frac{\\partial f(X,u)}{\\partial X} \\bigg|_{X_i, u_i}\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & -sin(\\theta)v\\Delta t & cos(\\theta)\\Delta t & 0 \\\\\n",
    "0 & 1 & cos(\\theta)v\\Delta t & sin(\\theta)\\Delta t & 0 \\\\\n",
    "0 & 0 & 1 & 0 & \\Delta t \\\\\n",
    "0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0\n",
    "\\end{bmatrix} \n",
    "\\end{align*}\n",
    "$$\n",
    "Predict state covariance\n",
    "$$\n",
    "P = FPF^{T}+Q\n",
    "$$\n",
    "Predict state\n",
    "$$\n",
    "\\bar X = f(X,u)\n",
    "$$\n",
    "Measurement residual. For our case, measurement funtion $h(X)$ is an identity function that returns $X$, and thus Jacobian of $h(X)$ is an identity matrix.\n",
    "$$\n",
    "y = z - h(X) = z - X\n",
    "$$\n",
    "$$\n",
    "H = \\frac{\\partial h(X)}{\\partial X} = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "0 & 1 & 0 & 0 & 0\\\\\n",
    "0 & 0 & 1 & 0 & 0\\\\\n",
    "0 & 0 & 0 & 1 & 0\\\\\n",
    "0 & 0 & 0 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Residual covariance\n",
    "$$\n",
    "S = HPH^{T}+R\n",
    "$$\n",
    "Near optimal Kalman gain\n",
    "$$\n",
    "K = PH^{T}S^{-1}\n",
    "$$\n",
    "update state\n",
    "$$\n",
    "X = X + Ky\n",
    "$$\n",
    "update state covariance\n",
    "$$\n",
    "P = (I-KH)P\n",
    "$$\n",
    "This is implemented in `ExtendedKalmanFilter.predict_and_update()` of `kalman.py`.\n",
    "```py\n",
    "    def predict_and_update(self, u, z):\n",
    "        assert(u.shape[0] == self.control_dim)\n",
    "        assert(z.shape[0] == self.measurement_dim)\n",
    "        F = self.compute_F()\n",
    "        self.move(u)\n",
    "        self.P = F @ self.P @ F.T + self.Q\n",
    "        y = z - self.X # use measurement model H(X) = X\n",
    "        y[2] = self.clip_theta(y[2])\n",
    "        S = self.H @ self.P @ self.H.T + self.R\n",
    "        S_inv = np.linalg.inv(S)\n",
    "        K = self.P @ self.H.T @ S_inv\n",
    "        self.X = self.X + K @ y\n",
    "        self.P = (np.eye(self.state_dim) - K @ self.H) @ self.P\n",
    "        self.state_trajectory.append(self.X)\n",
    "``` \n",
    "Consider a case where $\\theta_{i+1} = 0.01, \\theta_i = 2\\pi - 0.01$. Simple subtraction would yield \n",
    "$$ \n",
    "\\Delta\\theta = \\theta_{i+1} - \\theta = 0.02 - 2\\pi\n",
    "$$\n",
    ", but the value should be just 0.02./\n",
    "To prevent such overflow, we use `ExtendedKalmanFilter.clip_theta()` to keep $\\theta$ values in the range of $[-\\pi, \\pi]$.\n",
    "```py\n",
    "    def clip_theta(self, theta):\n",
    "        return (theta + np.pi) % (2 * np.pi) - np.pi\n",
    "``` \n",
    "In `kalman.ipynb` I tested my implementation with a simple simulation under noise. Despite initial state with large error, EKF is able to converge to true state.\n",
    "![My Image](figure/ekf_simulation.png)\n",
    "#### References\n",
    "Control your Thymio in Python, Basics of Mobile Robotics \\\n",
    "Solution 8, Basics of Mobile Robotics \\\n",
    "https://en.wikipedia.org/wiki/Extended_Kalman_filter \\\n",
    "https://github.com/rlabbe/filterpy \n",
    "\n",
    "##### Acknowledgement\n",
    "overall structure of ExtendedKalmanFilter class was inspired by https://github.com/grilloandrea6/mobile-robotics-project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Obstacle avoidance\n",
    "\n",
    "**Responsible:** Johann Lugon-Moulin\n",
    "\n",
    "**Slides intructions:** While navigating, the Thymio will have to use local navigation to avoid physical obstacles that can be put in its path at any point in time. You are free to choose what these physical objects are. (remove when completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 3. Running the project\n",
    "\n",
    "*TODO:* Add instructions on how to run the project, and show a video of the project working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
