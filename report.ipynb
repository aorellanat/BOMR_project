{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Mobile robots project\n",
    "\n",
    "<div style=\"border: 2px solid #4CAF50; border-radius: 10px; padding: 15px; background-color: #E8F5E9; color: #333;\">\n",
    "    <strong>T30 Members:</strong>\n",
    "    <ul>\n",
    "        <li>Jiwon You</li>\n",
    "        <li>Adriana Nancy Orellana Torrico</li>\n",
    "        <li>Charles Froessel</li>\n",
    "        <li>Johann Lugon-Moulin</li>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Project description\n",
    "\n",
    "## 1. Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- A good feature needs to be easy to extract and easy to match, robust to change in illumination, camera viewpoint and highly distinctive.\n",
    "- From 3D to 2D: perspective projection\n",
    "- Gaussian smoothing: removes high-frequency noise from the image with a gaussian kernel G\n",
    "- Edge detection: canny edge filter (combination of smoothing + edge detector into one operator) is an optimal detector, to reduce its cost we can numerically approximate its behavior computing the edge direction and magnitude with Sobel.\n",
    "- Sobel filter: from a row image convert to gray scale, then filter the image with gaussian or sobel filter, apply thresholding to get the edges, and finally non-maximum suppression to get the final edges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Components\n",
    "\n",
    "*TODO:* For each section, please explain how your imlementation works and how you have tested it. You can add diagrams, images or videos to make it easier to understand and show that your components are working as expected. Don't forget to cite external sources if you used any (even course materials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.1. Computer vision and image processing\n",
    "\n",
    "**Responsible:** Adriana Nancy Orellana Torrico\n",
    "\n",
    "**Slide intructions:** Your environment has to contain a set of obstacles that the Thymio avoids through global navigation. That is to say, the Thymio should avoid these obstacles without using the sensors to detect them. (remove when completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.2. Path planning\n",
    "\n",
    "**Responsible:** Charles Froessel\n",
    "\n",
    "**Slides intructions:** The objective is that the Thymio goes from an arbitrary position in the map to a target that can be placed anywhere in the environment. These will be changed during the demo to see how your system performs. (remove when completed) \n",
    "\n",
    "**Link for schematics (Use epfl account):** https://epflch-my.sharepoint.com/:p:/r/personal/charles_froessel_epfl_ch/_layouts/15/doc.aspx?sourcedoc=%7B20d9373d-95f6-4339-9879-352d763cab56%7D&action=edit ",
"\n",
    "

# The problem:

To perform global path planning, you first need a map of the environment. On this map, we need to find a starting position, corresponding to the robot's initial position. An arrival position is also added. This environment map is crucial to the robot's navigation: it enables us to generate the trajectory to be followed by the thymio and to impose constraints on its movement (for example, obstacles that will be forbidden zones). This map is a reduced representation of reality, and the choice of this model is crucial in generating the robot's behavior, and will therefore influence its overall performance.

## Representation of the environment:
*(from course: Note that most existing techniques assume a mass-less, holonomic, pointlike robot => may require low-level motion control and a priori expansion of obstacles to be implemented robustly)*

We can make grids, cells, visibility graphs, etc. We use visibility graphs to simplify calculations compared with grids and to ensure optimal trajectories (in terms of distance) between nodes.

So, we have a map consisting of a set of nodes and a mask:
- start (1 node)
- arrival (1 node)
- obstacle edge (variable, [0;~10^2])
- obstacle mask

Each node has 3 pieces of information:
- its number
- position (x, y)

The obstacle mask is used to check whether two nodes are connected (or visible to each other): two nodes separated by an obstacle cannot, therefore, be connected in our visibility graph. Moreover, two different obstacle nodes should be connected, even if a large distance separates them, provided the two nodes can see each other. 

This is the desired behavior: *(image case 1-2-3)*

Here, the goal and the Thymio can be connected by a straight-line trajectory that doesn't cross any obstacles. We therefore want our program to know that these two nodes are connected (despite their wide spacing). On the contrary, two nodes separated by an obstacle should be marked as unconnected.

We also want obstacle bypasses to be marked as feasible for the robot, so the obstacle mask must be smaller than the nodes *(image to do)*. Finally, we want to evaluate optimal trajectories when several objects are present.

We therefore decided to take an n*n matrix, which takes node numbers as indices. 0 everywhere, and 1 at row i column j if node i is connected to node j. This matrix is the connectivity matrix. This matrix is called the connectivity matrix. It lets us know which nodes are neighbors, which will be useful for the fastest path resolution algorithm. To obtain this matrix:





"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Motion control and pose estimation\n",
    "\n",
    "**Responsible:** Jiwon You\n",
    "\n",
    "**Slides intructions:** You will have to control the robot to help it move along the path. This requires an accurate estimate of the position of the robot which you will have to obtain through bayesian filtering. (remove when completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Obstacle avoidance\n",
    "\n",
    "**Responsible:** Johann Lugon-Moulin\n",
    "\n",
    "**Slides intructions:** While navigating, the Thymio will have to use local navigation to avoid physical obstacles that can be put in its path at any point in time. You are free to choose what these physical objects are. (remove when completed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 3. Running the project\n",
    "\n",
    "*TODO:* Add instructions on how to run the project, and show a video of the project working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
