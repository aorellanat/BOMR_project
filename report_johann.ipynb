{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Mobile robots project\n",
    "\n",
    "<div style=\"border: 2px solid #4CAF50; border-radius: 10px; padding: 15px; background-color: #E8F5E9; color: #333;\">\n",
    "    <strong>T30 Members:</strong>\n",
    "    <ul>\n",
    "        <li>Jiwon You</li>\n",
    "        <li>Adriana Nancy Orellana Torrico</li>\n",
    "        <li>Charles Froessel</li>\n",
    "        <li>Johann Lugon-Moulin</li>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Project description\n",
    "\n",
    "## 1. Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- A good feature needs to be easy to extract and easy to match, robust to change in illumination, camera viewpoint and highly distinctive.\n",
    "- From 3D to 2D: perspective projection\n",
    "- Gaussian smoothing: removes high-frequency noise from the image with a gaussian kernel G\n",
    "- Edge detection: canny edge filter (combination of smoothing + edge detector into one operator) is an optimal detector, to reduce its cost we can numerically approximate its behavior computing the edge direction and magnitude with Sobel.\n",
    "- Sobel filter: from a row image convert to gray scale, then filter the image with gaussian or sobel filter, apply thresholding to get the edges, and finally non-maximum suppression to get the final edges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Components\n",
    "\n",
    "*TODO:* For each section, please explain how your imlementation works and how you have tested it. You can add diagrams, images or videos to make it easier to understand and show that your components are working as expected. Don't forget to cite external sources if you used any (even course materials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.1. Computer vision and image processing\n",
    "\n",
    "**Responsible:** Adriana Nancy Orellana Torrico\n",
    "\n",
    "**Slide intructions:** Your environment has to contain a set of obstacles that the Thymio avoids through global navigation. That is to say, the Thymio should avoid these obstacles without using the sensors to detect them. (remove when completed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 2.2. Path planning\n",
    "\n",
    "**Responsible:** Charles Froessel\n",
    "\n",
    "**Slides intructions:** The objective is that the Thymio goes from an arbitrary position in the map to a target that can be placed anywhere in the environment. These will be changed during the demo to see how your system performs. (remove when completed) \n",
    "\n",
    "**Link for schematics (Use epfl account):** https://epflch-my.sharepoint.com/:p:/r/personal/charles_froessel_epfl_ch/_layouts/15/doc.aspx?sourcedoc=%7B20d9373d-95f6-4339-9879-352d763cab56%7D&action=edit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Pose estimation\n",
    "\n",
    "**Responsible:** Jiwon You\n",
    "\n",
    "#### 2.3.1 System Identification of a differetial drive robot\n",
    "Below are the names to denote state/control variables of Thymio. \\\n",
    "\\\n",
    "$u_l$ = left motor control input, `motor.left.target` \\\n",
    "$u_r$ = right motor control input, `motor.right.target` \\\n",
    "$u_{l,m}$ = measured left motor speed, `motor.left.speed` \\\n",
    "$u_{r,m}$ = measured left motor speed, `motor.right.speed` \\\n",
    "$v_{l}$ = linear velocity of left wheel \\\n",
    "$v_{r}$ = linear velocity of right wheel \\\n",
    "$v$ = linear velocity of Thymio \\\n",
    "$w$ = angular velocity of Thymio \n",
    "\n",
    "First, in `calibration.ipynb` I ran calibration code from exercise 8 to discover relationship between motor speed and linear velocity of Thymio. We will mainly use $u_l$ and $u_r$ around 100 to control Thymio, so we investigate linear velocity and motor speed variance at $u=100$. Moreover, we assume that conversion between motor speed and linear velocity is linear around this point. \\\n",
    "![My Image](figure/ground_sensor.png) \\\n",
    "\n",
    "Knowing that there is a thin white stripe between black blocks every 5cm, we can detect peaks from ground sensor and compute linear speed from the time it took to cross 6 blocks.\\\n",
    "\n",
    "It returned linear velocity = `3.26cm/s` for motor speed 100, and thus conversion factor from motor speed to linear velocity was `0.0326`. \\\n",
    "\n",
    "![My Image](figure/target_and_measured_speed_of_motor.png)\\\n",
    "\n",
    "In the histogram below, measured motor speed forms a Gaussian distribution around motor target speed of 100.\\\n",
    "\n",
    "![My Image](figure/measured_motor_speed_histogram.png)\n",
    "\n",
    "With $\\alpha$ as conversion factor and $L$ as Thymio wheel axle length,  \\\n",
    "$v_l = \\alpha u_l$ \\\n",
    "$v_r = \\alpha u_r$ \\\n",
    "$v = \\frac{v_l + v_r}{2}$ \\\n",
    "$w = \\frac{v_r - v_l}{L}$ \\\n",
    "Conversion between $v,w$ and $u_l, u_r$ is implemented in `utils.py`.\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\begin{bmatrix}\n",
    "v \\\\\n",
    "w\n",
    "\\end{bmatrix}\n",
    "&= TuningMatrix \\cdot\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\alpha}{2} & \\frac{\\alpha}{2} \\\\\n",
    "\\frac{-\\alpha}{L} & \\frac{\\alpha}{L} \n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix}\n",
    "u_l \\\\\n",
    "u_r\n",
    "\\end{bmatrix} = A\\cdot u \n",
    "\\end{align*}\n",
    "$$ //\n",
    "```py\n",
    "    wheel_axle_length = 9.5 # in cm\n",
    "    thymio_speed_to_cms = 0.03260\n",
    "    A = thymio_speed_to_cms* np.array([[0.5, 0.5],[-1/wheel_axle_length, 1/wheel_axle_length]]) # theoretical kinematics model, but is understimating\n",
    "    tuning_matrix = np.array([[1.65,1.65],[2,2]])# compensate for underestimation\n",
    "    A = np.multiply(tuning_matrix, A)\n",
    "\n",
    "    def from_u_to_vw(ul, ur):\n",
    "        vw = A@np.array([ul, ur]) \n",
    "        return vw[0], vw[1] # returns v, w in cm/s, rad/s\n",
    "\n",
    "    def from_vw_to_u(v,w):\n",
    "        A_inv = np.linalg.inv(A)\n",
    "        ulur = A_inv @ np.array([v,w]) \n",
    "        return int(ulur[0]), int(ulur[1]) # returns ul, ur as int\n",
    "```\n",
    "Note that in reality, theoretical conversion model was underestimating actual v and w. For a quick fix, I added empirically tuned `tuning_matrix` to compensate for underestimation. \n",
    "\n",
    "Let $X = (x,y,\\theta, v, w)^{T}$ denote Thymio state. Discrete time motion model of Thymio is as follows. In particular, we use $v_{i}$ and $w_{i}$ as a temporary prediction of $v_{i+1}$ and $w_{i+1}$. This is reasonable because in our control policy Thymio is moving at constant speed in each control phase(`path_following`, `local_avoidance`, `get_back_to_path`, which will be further explained in motion control section). \n",
    "$$\n",
    "\\begin{align*}\n",
    "X_{i+1} \n",
    "&= f(X_i, u_i) \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "x_i + v_i\\cdot cos(\\theta_i)\\Delta t\\\\\n",
    "y_i + v_i\\cdot sin(\\theta_i)\\Delta t\\\\\n",
    "\\theta_i + w_i\\cdot\\Delta t \\\\\n",
    "v_{i}\\\\\n",
    "w_{i}\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{align*}\n",
    "$$ \n",
    "This is implemented in `ExtendedKalmanFilter.move(u)` of `kalman.py`, which is  the state prediction step.\\\n",
    "```py\n",
    "    def move(self, u):\n",
    "        assert(u.shape[0] == 2) # u is np.array containing v_,w_\n",
    "        x,y,theta,v,w = self.X\n",
    "        # v_, w_ = u\n",
    "        self.X[0] = x + v*np.cos(theta)*self.dt \n",
    "        self.X[1] = y + v*np.sin(theta)*self.dt\n",
    "        self.X[2] = self.clip_theta(theta + w * self.dt)\n",
    "        self.X[3] = v \n",
    "        self.X[4] = w\n",
    "``` \n",
    "\n",
    "#### 2.3.2 Process and measurement noise\n",
    "For Kalman Filter, let Q denote process noise matrix, R measurement noise matrix, $R_c$ camera noise matrix, $R_{vw}$ linear/angular velocity measurement noise matrix. Since we can't really estimate process noise, I used empirical tuning for Q. \n",
    "$$\n",
    "R = \n",
    "\\begin{bmatrix}\n",
    "R_c & 0 \\\\\n",
    "0 & R_{vw}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Measurement noise is split into camera noise and vw noise. It is safe to assume that camera noise and vw noise are uncorrelated, and thus R is in block diagonal form. \\\n",
    "\n",
    "Camera measurements are faily accurate, and we can use a small value for camera noise. However, when aruco marker on Thymio is blocked, camera cannot detect Thymio. For such case, camera will return $(x_{cam}, y_{cam}, \\theta_{cam}) = (0, 0, 0)$ and camera noise will be set to infinity, which excludes camera measurement from updating Thymio state. This is implemented in `ExtendedKalmanFilter.switch_mode()` of `kalman.py`.\\\n",
    "```py\n",
    "    NOISE_COV_CAMERA = 0.0001*np.eye(3)\n",
    "    NOISE_COV_CAMERA_BLOCKED=9999999*np.eye(3)\n",
    "    def switch_mode(self, camera_blocked):\n",
    "        if camera_blocked and self.camera_available:\n",
    "            self.R[0:3, 0:3] = NOISE_COV_CAMERA_BLOCKED\n",
    "            self.camera_available = False\n",
    "        elif not camera_blocked and not self.camera_available:\n",
    "            self.R[0:3,0:3] = NOISE_COV_CAMERA\n",
    "            self.camera_available = True\n",
    "``` \n",
    "We have previously seen that motor speed measurement noise resembles Gaussian. Since we have direct access to motor speed measurement, we can easily compute motor speed variance. We assume that noise from left and right motor are uncorrelated.\\\n",
    "![My Image](figure/target_and_measured_speed_of_motor.png)\\\n",
    "\n",
    "Then using linear transformation from `utils.py`, we can convert motor speed variance to linear/angular velocity variance. As in 2.3.1, $\\alpha$ denotes Thymio speed conversion factor.\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\begin{bmatrix}\n",
    "v \\\\\n",
    "w\n",
    "\\end{bmatrix}\n",
    "&= TuningMatrix \\cdot\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\alpha}{2} & \\frac{\\alpha}{2} \\\\\n",
    "\\frac{-\\alpha}{L} & \\frac{\\alpha}{L} \n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix}\n",
    "u_l \\\\\n",
    "u_r\n",
    "\\end{bmatrix} = A\\cdot u \\\\\n",
    "\\Sigma_{u} &= \n",
    "\\begin{bmatrix}\n",
    "\\sigma_{ul}^2 & 0 \\\\\n",
    "0 & \\sigma_{ur}^2\n",
    "\\end{bmatrix} \\\\\n",
    "\\Sigma_{vw} &= A\\Sigma_{u} A^T\n",
    "\\end{align*}\n",
    "$$ //\n",
    "```py\n",
    "    from utils import A\n",
    "    var_l_speed = np.var(l_speed[idx:]) # took from idx to avoid the initial transient and devid by the conversion factor\n",
    "    var_r_speed = np.var(r_speed[idx:])\n",
    "    cov_vw = A @ np.array([[var_l_speed,0],[0, var_r_speed]]) @ A.T\n",
    "```\n",
    "$$\n",
    "R_{vw} =\n",
    "\\begin{bmatrix}\n",
    "0.0227 & -0.0022 \\\\\n",
    "-0.0022 & 0.0014\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Note that $R_{vw}$ is not diagonal. This agrees with our intuition that linear/angular velocity noise are correlated.\n",
    "#### 2.3.3 Extended Kalman Filter implementation\n",
    "Since our Thymio is a time-variant nonlinear system and noises can be assumed as Gaussian, we are using Extended Kalman Filter.\n",
    "$$\n",
    "\\begin{align*}\n",
    "X_{i+1} \n",
    "&= f(X_i, u_i) \\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "x_i + v_i\\cdot cos(\\theta_i)\\Delta t\\\\\n",
    "y_i + v_i\\cdot sin(\\theta_i)\\Delta t\\\\\n",
    "\\theta_i + w_i\\cdot\\Delta t \\\\\n",
    "v_{i}\\\\\n",
    "w_{i}\n",
    "\\end{bmatrix} \\\\\n",
    "y &= h(X) = X\n",
    "\\end{align*}\n",
    "$$ \n",
    "First we compute Jacobian of $f(X_i, u_i)$ to linearize our system.\n",
    "$$\n",
    "\\begin{align*}\n",
    "F\n",
    "&= \\frac{\\partial f(X,u)}{\\partial X} \\bigg|_{X_i, u_i}\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & -sin(\\theta)v\\Delta t & cos(\\theta)\\Delta t & 0 \\\\\n",
    "0 & 1 & cos(\\theta)v\\Delta t & sin(\\theta)\\Delta t & 0 \\\\\n",
    "0 & 0 & 1 & 0 & \\Delta t \\\\\n",
    "0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1\n",
    "\\end{bmatrix} \n",
    "\\end{align*}\n",
    "$$\n",
    "Predict state covariance\n",
    "$$\n",
    "P = FPF^{T}+Q\n",
    "$$\n",
    "Predict state\n",
    "$$\n",
    "\\bar X = f(X,u)\n",
    "$$\n",
    "Measurement residual. For our case, measurement funtion $h(X)$ is an identity function that returns $X$, and thus Jacobian of $h(X)$ is an identity matrix.\n",
    "$$\n",
    "y = z - h(X) = z - X\n",
    "$$\n",
    "$$\n",
    "H = \\frac{\\partial h(X)}{\\partial X} = \n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0\\\\\n",
    "0 & 1 & 0 & 0 & 0\\\\\n",
    "0 & 0 & 1 & 0 & 0\\\\\n",
    "0 & 0 & 0 & 1 & 0\\\\\n",
    "0 & 0 & 0 & 0 & 1\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "Residual covariance\n",
    "$$\n",
    "S = HPH^{T}+R\n",
    "$$\n",
    "Near optimal Kalman gain\n",
    "$$\n",
    "K = PH^{T}S^{-1}\n",
    "$$\n",
    "update state\n",
    "$$\n",
    "X = X + Ky\n",
    "$$\n",
    "update state covariance\n",
    "$$\n",
    "P = (I-KH)P\n",
    "$$\n",
    "This is implemented in `ExtendedKalmanFilter.predict_and_update()` of `kalman.py`.\n",
    "```py\n",
    "    def predict_and_update(self, u, z):\n",
    "        assert(u.shape[0] == self.control_dim)\n",
    "        assert(z.shape[0] == self.measurement_dim)\n",
    "        # prediction step\n",
    "        F = self.compute_F()\n",
    "        self.move(u)\n",
    "        self.P = F @ self.P @ F.T + self.Q\n",
    "\n",
    "        #update step\n",
    "        y = z - self.X # use measurement model H(X) = X\n",
    "        y[2] = self.clip_theta(y[2]) # clip theta to prevent overflow\n",
    "        S = self.H @ self.P @ self.H.T + self.R\n",
    "        S_inv = np.linalg.inv(S)\n",
    "        K = self.P @ self.H.T @ S_inv\n",
    "        self.X = self.X + K @ y\n",
    "        self.P = (np.eye(self.state_dim) - K @ self.H) @ self.P\n",
    "        self.state_trajectory.append(self.X)\n",
    "``` \n",
    "Consider a case where $\\theta_{i+1} = 0.01, \\theta_i = 2\\pi - 0.01$. Simple subtraction would yield \n",
    "$$ \n",
    "\\Delta\\theta = \\theta_{i+1} - \\theta_i = 0.02 - 2\\pi\n",
    "$$\n",
    ", but the value should be just 0.02.\n",
    "\n",
    "To prevent such overflow, we use `ExtendedKalmanFilter.clip_theta()` to keep $\\theta$ values in the range of $[-\\pi, \\pi]$.\n",
    "```py\n",
    "    def clip_theta(self, theta):\n",
    "        return (theta + np.pi) % (2 * np.pi) - np.pi\n",
    "``` \n",
    "In `kalman.ipynb` I tested my implementation with a simple simulation under noise. Despite initial state with large error, EKF is able to converge to true state.\n",
    "![My Image](figure/ekf_simulation.png)\n",
    "#### References\n",
    "Control your Thymio in Python, Basics of Mobile Robotics \\\n",
    "Solution 8, Basics of Mobile Robotics \\\n",
    "https://en.wikipedia.org/wiki/Extended_Kalman_filter \\\n",
    "https://github.com/rlabbe/filterpy \n",
    "\n",
    "##### Acknowledgement\n",
    "overall structure of ExtendedKalmanFilter class was inspired by https://github.com/grilloandrea6/mobile-robotics-project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Motion Control\n",
    "\n",
    "**schematic of how motion control work**\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"figure/motion_control.jpg\" alt=\"motioncontr\" style=\"width:70%;\"/>\n",
    "</div>\n",
    "\n",
    "**fonction : find_how_go to next target**\n",
    "<br>\n",
    "\n",
    "When we are in the path following, The thymio turn to the direction of the next point and then go straight to it. The global path to avoid the object on the ground is made of straight lines. If we make curves, it can happend that we go on this object because we dont' recompute the path every loop. So to avoid this situation, turn and then go straight is the best way to to do.\n",
    "\n",
    "code:\n",
    "```py\n",
    "    dx = x_goal - x\n",
    "    dy = y_goal - y\n",
    "\n",
    "    # Conversion in polar coordinates\n",
    "    alpha = np.arctan2(dy, dx) - theta  # angle relative to the target\n",
    "    alpha = (alpha + np.pi)%(2*np.pi) - np.pi\n",
    "\n",
    "    desired_theta = np.arctan2(dy, dx)\n",
    "    dtheta = (desired_theta - theta + np.pi)% (2*np.pi) - np.pi\n",
    "    if abs(dtheta) > 3*np.pi / 180: # abs(dtheta) larger than 3 degree\n",
    "        v_ = 0\n",
    "        w_ = np.sign(dtheta)*0.314 #turn on himself\n",
    "    else:\n",
    "        v_ = 3.3 #go straight\n",
    "        w_ = 0\n",
    "    return v_, w_\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Obstacle avoidance\n",
    "\n",
    "**Responsible:** Johann Lugon-Moulin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided that for the local avoidance we use only the IR sensors to detecte the object and for avoiding the obstacle too. Our Robot is like blinded to bes sur that he can handled every obstacle even if the camera is down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step1** \n",
    "<br> \n",
    "\n",
    "Thymio take the new path and go to the next_target in the dessin the goal \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"figure/localnav_step1.png\" alt=\"Step1\" style=\"width:70%;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2** \n",
    "<br> \n",
    "\n",
    "Obstacle detected with IR sensor . Change mode to « local_avoidance » and then check if sensors left have higher value than right. Update X_entrance and Y-entrance and angle at entrance\n",
    "$$\n",
    "\\text{Sensors left} > \\text{Sensors right} \\implies \\text{wall\\_on} = \\text{left}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Sensors right} > \\text{Sensors left} \\implies \\text{wall\\_on} = \\text{right}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"figure/localnav_step2.png\" alt=\"Step2\" style=\"width:70%;\"/>\n",
    "</div>\n",
    "<br>\n",
    "Code:\n",
    "<br>\n",
    "\n",
    "```py\n",
    "   if self.control_mode == \"path_following\":\n",
    "            activate_local_avoidance = local_avoidance.check_obstacle(prox_horizontal)\n",
    "            if activate_local_avoidance:\n",
    "                self.control_mode = \"local_avoidance\"\n",
    "                self.local_nav.initialize(prox_horizontal)\n",
    "                print(\"local avoidance activated\")\n",
    "                self.x_entrance = x\n",
    "                self.y_entrance = y\n",
    "                self.alpha_entrance = theta\n",
    "``` \n",
    "```py\n",
    "        def initialize(self, prox_horizontal):\n",
    "        if prox_horizontal[0]+ prox_horizontal[1]<=prox_horizontal[3] + prox_horizontal[4]:\n",
    "            self.wall_on = \"right\"\n",
    "            self.mode = \"turning\"\n",
    "            print(f\"local nav mode = {self.mode}, wall on {self.wall_on}\")\n",
    "        else:\n",
    "            self.wall_on = \"left\"\n",
    "            self.mode = \"turning\"\n",
    "            print(f\"local nav mode = {self.mode}, wall on {self.wall_on}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**\n",
    "<br>\n",
    "\n",
    "Thymio turn ( right or left like we check before) on himself until he don’t see the object. Then the local avoidance mode became wall_following  \n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"figure/localnav_step3.png\" alt=\"Step3\" style=\"width:70%;\"/>\n",
    "</div>\n",
    "<br>\n",
    "code:\n",
    "<br>\n",
    "\n",
    "```py\n",
    "    if self.mode == \"turning\":\n",
    "            if self.wall_on == \"right\":\n",
    "                v = -1\n",
    "                w = 0.314\n",
    "                if all(np.array(prox_horizontal[2:]) < 150):\n",
    "                    self.mode = \"wall_following\"\n",
    "                    print(f\"{self.mode} on {self.wall_on} activated\")\n",
    "            elif self.wall_on == \"left\":\n",
    "                v = -1\n",
    "                w = - 0.314\n",
    "                if all(np.array(prox_horizontal[0:3]) < 150):\n",
    "                    self.mode = \"wall_following\"\n",
    "                    print(f\"{self.mode} on {self.wall_on} activated\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**\n",
    "<br>\n",
    "\n",
    "Thymio go forward with small curve and when a sensor see the obstacle he continue to go forward but the curve is an other way (go far away from object) until he don’t se the obstacle again. He make this switch all the way of local avoidance\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"figure/localnav_step4.png\" alt=\"Step4\" style=\"width:70%;\"/>\n",
    "</div><br>\n",
    "code :\n",
    "<br>\n",
    "\n",
    "```py\n",
    "     elif self.mode == \"wall_following\":\n",
    "            if self.wall_on == \"right\":\n",
    "                if all(np.array(prox_horizontal[2:]) < 150): # not seeing the wall on right, turning right\n",
    "                    v, w = 3, -0.25\n",
    "                else: # seeing the wall, move and turn slightly left\n",
    "                    v, w = 3, 0.3\n",
    "            if self.wall_on == \"left\":\n",
    "                if all(np.array(prox_horizontal[0:3]) < 150): # not seeing the wall on left, turning left\n",
    "                    v, w = 3, 0.25\n",
    "                else: # seeing the wall, move and turn slightly right\n",
    "                    v, w = 3, -0.3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5**\n",
    "<br>\n",
    "\n",
    "Thymio have the point at the beginning(green) and the real position(blue point)\n",
    "<br>\n",
    "\n",
    "if the condition under is right so we are back on path. \n",
    "$$arctan ((y_{entrance} – y) / (x_{entrance} –x)) = alpha_{entrance}$$\n",
    " Change motion_control to get_back to path and take the position (x,y,$alpha$) at the exit\n",
    "<br>\n",
    "\n",
    "$alpha$ is the angle of the robot from the x axis\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"figure/localnav_step5.png\" alt=\"Step5\" style=\"width:70%;\"/>\n",
    "</div>\n",
    "<br>\n",
    "code:\n",
    "<br>\n",
    "\n",
    "```py\n",
    "    elif self.control_mode == \"local_avoidance\":\n",
    "                get_back_to_path = self.activate_get_back_to_path(x,y, theta)\n",
    "                if get_back_to_path:\n",
    "                    print(\"getting back to path activated\")\n",
    "                    self.control_mode = \"get_back_to_path\"\n",
    "                    self.x_exit = x\n",
    "                    self.y_exit = y\n",
    "```\n",
    "\n",
    "```py\n",
    "    def activate_get_back_to_path(self, x, y, theta):\n",
    "        dy = y - self.y_entrance\n",
    "        dx = x - self.x_entrance\n",
    "        alpha = np.arctan2(dy, dx)\n",
    "        #d_alpha = (theta - self.alpha_entrance + np.pi) % (2*np.pi) - np.pi\n",
    "        d_alpha = (alpha - self.alpha_entrance + np.pi) % (2*np.pi) - np.pi\n",
    "        return ( abs(d_alpha) < 0.1 and np.sqrt(dy**2 + dx**2) > 5 ) # if alpha is small enough, assume that Thymio is back on track\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6**\n",
    "<br>\n",
    "\n",
    "Thymio go forward at turn dépend on the direction  to go a little bit far away from the object. When he is 4 cm away (enough for the thymio to turn on itself) we change the motion control mode to path_following and recompute the global_path \n",
    "<br><br>\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"figure/localnav_step6.png\" alt=\"Step6\" style=\"width:70%;\"/>\n",
    "</div>\n",
    "<br>\n",
    "code:\n",
    "<br>\n",
    "\n",
    "```py\n",
    "   elif self.control_mode == \"get_back_to_path\":\n",
    "            if self.local_nav.wall_on == \"right\":\n",
    "                v, w = 2, 0.314\n",
    "            else:\n",
    "                v, w = 2, -0.314\n",
    "```    \n",
    "\n",
    "```py\n",
    "   elif self.control_mode == \"get_back_to_path\":\n",
    "            #dtheta = (theta - self.alpha_entrance + np.pi) % (2*np.pi) - np.pi\n",
    "            distance = np.sqrt(x - self.x_exit, y - self.y_exit)\n",
    "            if distance > 3: # has moved far enough from exit point\n",
    "                self.control_mode = \"path_following\"\n",
    "                recompute_global_path = True\n",
    "                print(\"path following activated activated\")\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7**\n",
    "<br>\n",
    "\n",
    "Thymio take the new path and go to the next_target in the dessin the goal \n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"figure/localnav_step7.png\" alt=\"Step7\" style=\"width:70%;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 3. Running the project\n",
    "Run `main.py`. In particular, depending on laptop, `CAMERA_ID` can be 0 or 1.\n",
    "\n",
    "First it connects to Thymio and opens a camera window.\n",
    "include image\n",
    "\n",
    "Press `m` key to detect the map, obstacles and fix map perspective.\n",
    "include image\n",
    "\n",
    "After placing Thymio on the map, press `p` key to find global path and start motion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schematics of main loop**\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"figure/bigschematics.jpg\" alt=\"Schematics\" style=\"width:70%;\"/>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Explanation of main loop\n",
    "Main loop roughly consists of 3 parts; map detection, path planning and start motion. Step 1 is run only once in the beginning. There are various flags such as `kidnapping`, `start_motion` and `path_planning` to activate or deactivate step 2 and 3.\n",
    "```py\n",
    "    while True:\n",
    "        if map_detection:\n",
    "            # Step 1: Detect the map\n",
    "        if path_planning:\n",
    "            # Step 2: Path planning\n",
    "        if start_motion:\n",
    "            # Step 3: Start motion\n",
    "``` \n",
    "\n",
    "'start_motion' step is the actual control loop, whose steps are roughly as follows.\n",
    "\n",
    "```py\n",
    "    if start_motion:\n",
    "        # get data from camera\n",
    "        # get data from Thymio\n",
    "        # check if Thymio is visible on camera\n",
    "        # check if Thymio is kidnapped\n",
    "        # update Thymio state using EKF\n",
    "        # check if next target is reached\n",
    "        # compute control input and set Thymio target velocity\n",
    "``` \n",
    "\n",
    "`path` variable is a list of nodes to visit, including the goal. `next_target` is the next node to visit. Every time a node is reached, Thymio pops its `next_target` from `path`. If `path` is empty, it means Thymio has reached the goal and the main loop terminates.\n",
    "```py\n",
    "    target_reached = np.linalg.norm(np.array([x - next_target[0], y - next_target[1]])) < epsilon\n",
    "    if target_reached:\n",
    "        if len(path) == 0:\n",
    "            print(\"Goal reached, terminating...\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Heading towards next waypoint\")\n",
    "            next_target = path.pop(0)\n",
    "``` \n",
    "When Thymio detects kidnapping from acceleration, it sets motor target speed to 0 and activates `path_planning`. \n",
    "```py\n",
    "    # to detect kidnapping\n",
    "    if abs(acc[2]-22)>4: # sudden change in acc_z indicates kidnapping\n",
    "        print(\"kidnapping detected\")\n",
    "        kidnapping = True\n",
    "        thymio.node.send_set_variables(motors(0,0))\n",
    "        # computes new global path in the next iteration\n",
    "        path_planning = True\n",
    "        continue\n",
    "``` \n",
    "Thymio will start moving only when a new path is computed, and a new path is computed only when kidnapping is over. We use ground sensors to check if kidapping is over, because acceleration sensor cannot differentiate between being on the ground and being held still in the air.\n",
    "```py\n",
    "    if path_planning:\n",
    "        if kidnapping:\n",
    "            aw(thymio.client.sleep(dt))\n",
    "            data = thymio.get_data()\n",
    "            prox_ground_delta = data[2]\n",
    "            print(f\"kidnapping, {prox_ground_delta[0]}\")\n",
    "            if prox_ground_delta[0] > 700: \n",
    "                kidnapping = False # kidnapping is over\n",
    "                print(\"kidnapping finished\")\n",
    "                continue\n",
    "        if thymio_found and goal_coords and not kidnapping:\n",
    "            obstacle_vertices = get_obstacle_vertices(obstacles_contours)\n",
    "            global_path = compute_global_path(thymio_coords, goal_coords, obstacle_vertices, mask_obstacles)\n",
    "            # ...\n",
    "            path = global_path.copy().tolist()\n",
    "            # global_path is for visualization, and thus in pixel coordinates\n",
    "            # convert to xy coordinates in centimeters\n",
    "            path = [convert_pixel_to_cm(target, REAL_MAP_WIDTH_CM, REAL_MAP_HEIGHT_CM, MAP_MAX_WIDTH, MAP_MAX_HEIGHT) for target in path]\n",
    "            next_target = path.pop(0)\n",
    "            # once path is computed, start motion and deactivate path planning\n",
    "            start_motion=True\n",
    "            path_planning = False\n",
    "            mc.control_mode = \"path_following\"\n",
    "``` \n",
    "\n",
    "Motion controller `mc` decides control phase, namely `path_following`, `local_avoidance.turning`, `local_avoidance.wall_following` and `get_back_to_path`. Nominal phase is `path_following`. When a local obstacle is first detected, Thymio will sequentially switch to `local_avoidance.turning`, `local_avoidance.wall_following` and `get_back_to_path` phase. \n",
    "``` py\n",
    "    path_planning = mc.set_mode(prox_horizontal, x, y, theta)\n",
    "    ul, ur = mc.compute_control(x, y, theta, next_target[0], next_target[1], prox_horizontal)\n",
    "    thymio.node.send_set_variables(motors(ul, ur))\n",
    "    aw(thymio.client.sleep(dt))\n",
    "``` \n",
    "Note that during local avoidance, motion controller's primary goal is to avoid the local obstacle, and often moves past the next target node of the original global path. Therefore, when `get_back_to_path` is completed, we activate path planning again.\n",
    "\n",
    "Finally, when Thymio aruco marker is blocked and EKF is only using speed sensor measurements, state uncertainty will accumulate. To visualize this, we add position uncertainty ellipse, which is obtained from P matrix of `ekf`.\n",
    "``` py\n",
    "    xy_variance = ekf.P[0:2, 0:2]\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(xy_variance)\n",
    "    ellipse_axis_length = convert_cm_length_to_pixel(np.sqrt(eigenvalues),REAL_MAP_WIDTH_CM, REAL_MAP_HEIGHT_CM, MAP_MAX_WIDTH, MAP_MAX_HEIGHT)\n",
    "    ellipse_angle = np.arctan2(eigenvectors[0][1], eigenvectors[0][0])\n",
    "    ellipse_angle = np.rad2deg(-ellipse_angle)\n",
    "    cv2.ellipse(map_frame, ekf_pixel, ellipse_axis_length, ellipse_angle, 0, 360, (0,255,255), 5)\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Comments on demo video\n",
    "\n",
    "Green dot/arrow marks Thymio position and heading from camera. Purple dot/arrow marks Thymio position and heading estimated by EKF.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lr24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
